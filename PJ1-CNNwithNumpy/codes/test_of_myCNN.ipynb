{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-08T15:12:51.029866Z",
     "start_time": "2025-04-08T15:12:50.870786Z"
    }
   },
   "source": [
    "from abc import abstractmethod\n",
    "import numpy as np\n",
    "\n",
    "class Layer():\n",
    "    def __init__(self) -> None:\n",
    "        self.optimizable = True\n",
    "    \n",
    "    @abstractmethod\n",
    "    def forward():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def backward():\n",
    "        pass\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T11:56:16.174283Z",
     "start_time": "2025-04-08T11:56:16.155377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class conv2D(Layer):\n",
    "    \"\"\"\n",
    "    The 2D convolutional layer. Try to implement it on your own.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, initialize_method=np.random.normal, weight_decay=False, weight_decay_lambda=1e-8) -> None:\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        self.filters = initialize_method(size=(out_channels, in_channels, self.kernel_size, self.kernel_size))\n",
    "        # [out_channels, in_channels, kernel, kernel]\n",
    "        self.bias = np.zeros((out_channels,))\n",
    "\n",
    "        self.grads = {'W': None, 'b': None}\n",
    "        self.input = None  # Record the input for backward process.\n",
    "\n",
    "        self.params = {'W': self.filters, 'b': self.bias}\n",
    "\n",
    "        self.weight_decay = weight_decay  # whether using weight decay\n",
    "        self.weight_decay_lambda = weight_decay_lambda  # control the intensity of weight decay\n",
    "\n",
    "    def __call__(self, X) -> np.ndarray:\n",
    "        return self.forward(X)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        input X: [batch, channels, H, W]\n",
    "        W : [1, out, in, k, k]\n",
    "        no padding\n",
    "        \"\"\"\n",
    "\n",
    "        self.input = X\n",
    "        batch_size, in_channels, H_in, W_in = X.shape\n",
    "        k = self.kernel_size\n",
    "\n",
    "        # padding\n",
    "        if self.padding > 0:\n",
    "            X_padded = np.pad(X, ((0, 0), (0, 0), (self.padding,) * 2, (self.padding,) * 2))\n",
    "        else:\n",
    "            X_padded = X\n",
    "            \n",
    "        print(\"Padded Input:\")\n",
    "        print(X_padded)\n",
    "\n",
    "        H_out = (H_in + 2 * self.padding - k) // self.stride + 1\n",
    "        W_out = (W_in + 2 * self.padding - k) // self.stride + 1\n",
    "        output = np.zeros((batch_size, self.out_channels, H_out, W_out))\n",
    "\n",
    "        # 计算卷积\n",
    "        for i in range(H_out):\n",
    "            h_start = i * self.stride\n",
    "            h_end = h_start + k\n",
    "            for j in range(W_out):\n",
    "                w_start = j * self.stride\n",
    "                w_end = w_start + k\n",
    "\n",
    "                window = X_padded[:, :, h_start:h_end, w_start:w_end]\n",
    "                output[:, :, i, j] = np.tensordot(\n",
    "                    window, self.filters, axes=([1, 2, 3], [1, 2, 3])\n",
    "                ) + self.bias\n",
    "        print(\"Convolution Output:\")\n",
    "        print(output)\n",
    "        return output\n",
    "\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def backward(self, grads):\n",
    "        \"\"\"\n",
    "        grads : [batch_size, out_channel, new_H, new_W]\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size, out_channels, H_out, W_out = grads.shape\n",
    "        k = self.kernel_size\n",
    "\n",
    "        # 初始化梯度\n",
    "        dX = np.zeros_like(self.input, dtype=np.float64)  # 确保使用float64\n",
    "        dfilters = np.zeros_like(self.filters, dtype=np.float64)  # 确保使用float64\n",
    "        dbias = np.zeros_like(self.bias, dtype=np.float64)  # 确保使用float64\n",
    "\n",
    "        # 旋转卷积核（关键步骤）\n",
    "        rotated_filters = np.rot90(self.filters, 2, axes=(2, 3))\n",
    "        rotated_filters=self.filters\n",
    "\n",
    "        # 处理padding\n",
    "        if self.padding > 0:\n",
    "            X_padded = np.pad(self.input,\n",
    "                              ((0, 0), (0, 0), (self.padding,) * 2, (self.padding,) * 2))\n",
    "            dX_padded = np.pad(dX,\n",
    "                               ((0, 0), (0, 0), (self.padding,) * 2, (self.padding,) * 2))\n",
    "        else:\n",
    "            X_padded = self.input\n",
    "            dX_padded = dX\n",
    "            \n",
    "        # print(\"padded X:\",X_padded)\n",
    "        # print(\"padded dX:\",dX_padded)\n",
    "\n",
    "        for i in range(H_out):\n",
    "            for j in range(W_out):\n",
    "                h_start = i * self.stride\n",
    "                w_start = j * self.stride\n",
    "                window = X_padded[:, :, h_start:h_start + k, w_start:w_start + k]\n",
    "\n",
    "                # 1. 计算滤波器梯度（修正转置问题）\n",
    "                dfilters += np.tensordot(\n",
    "                    grads[:, :, i, j],  # shape: (batch, out_ch)\n",
    "                    window,  # shape: (batch, in_ch, k, k)\n",
    "                    axes=([0], [0])  # 沿着batch维度做点积\n",
    "                )  # 结果形状: (out_ch, in_ch, k, k)\n",
    "\n",
    "                # 2. 计算输入梯度（修正维度扩展）\n",
    "                grad_slice = grads[:, :, i, j][:, :, np.newaxis, np.newaxis,\n",
    "                             np.newaxis]  # shape: (batch, out_ch, 1, 1, 1)\n",
    "                dX_padded[:, :, h_start:h_start + k, w_start:w_start + k] += np.sum(\n",
    "                    grad_slice * rotated_filters[np.newaxis, :, :, :, :],  # shape: (1, out_ch, in_ch, k, k)\n",
    "                    axis=1  # 沿out_ch维度求和\n",
    "                )  # 结果形状: (batch, in_ch, k, k)\n",
    "\n",
    "                # 3. 计算偏置梯度（修正索引方式）\n",
    "                dbias += np.sum(grads[:, :, i, j], axis=0)  # 向量化计算\n",
    "\n",
    "                # print(f\"位置({i},{j})\")\n",
    "                # print(\"滤波器梯度增量:\", np.sum(dfilters))\n",
    "                # print(\"输入梯度增量:\", np.sum(dX_padded))\n",
    "\n",
    "        # 去除padding\n",
    "        if self.padding > 0:\n",
    "            dX = dX_padded[:, :, self.padding:-self.padding, self.padding:-self.padding]\n",
    "\n",
    "        # 权重衰减\n",
    "        if self.weight_decay:\n",
    "            dfilters += 2 * self.weight_decay_lambda * self.filters\n",
    "\n",
    "        self.grads['W'] = dfilters/batch_size\n",
    "        self.grads['b'] = dbias/batch_size\n",
    "        \n",
    "        # print(\"dW\",self.grads['W'])\n",
    "        # print(\"dbias\",self.grads['b'])\n",
    "        # print(\"dX\",dX)\n",
    "        return dX\n",
    "    \n",
    "    def clear_grad(self):\n",
    "        self.grads = {'W' : None, 'b' : None}"
   ],
   "id": "6626891749546b6c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T11:55:06.448846Z",
     "start_time": "2025-04-08T11:55:06.443100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layer=conv2D(in_channels=1,out_channels=1,kernel_size=3,stride=1,padding=1)\n",
    "layer.filters = np.array([[[[1, 0, -1], [1, 0, -1], [1, 0, -1]]]])  # 经典的边缘检测核\n",
    "layer.bias = np.array([0])  # 设定偏置为 0\n",
    "X = np.array([[[[1, 2, 3],\n",
    "                [4, 5, 6],\n",
    "                [7, 8, 9]]]])\n",
    "\n",
    "ans=layer(X)\n"
   ],
   "id": "284a01c03500ffc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded Input:\n",
      "[[[[0 0 0 0 0]\n",
      "   [0 1 2 3 0]\n",
      "   [0 4 5 6 0]\n",
      "   [0 7 8 9 0]\n",
      "   [0 0 0 0 0]]]]\n",
      "Convolution Output:\n",
      "[[[[ -7.  -4.   7.]\n",
      "   [-15.  -6.  15.]\n",
      "   [-13.  -4.  13.]]]]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T10:00:57.131265Z",
     "start_time": "2025-04-03T10:00:57.125530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layer=conv2D(in_channels=1,out_channels=2,kernel_size=3,stride=1,padding=1)\n",
    "\n",
    "layer.filters = np.array([\n",
    "    [[[1, 1, 1],  \n",
    "      [1, 1, 1],  \n",
    "      [1, 1, 1]]],  # 第一组卷积核（全 1），形状 (1,3,3)\n",
    "\n",
    "    [[[2, 2, 2],  \n",
    "      [2, 2, 2],  \n",
    "      [2, 2, 2]]],  # 第二组卷积核（全 2），形状 (1,3,3)\n",
    "])\n",
    "\n",
    "\n",
    "layer.bias = np.array([0, 0]) # 设定偏置为 0\n",
    "print(layer.filters.shape)\n",
    "print(layer.bias.shape)\n",
    "\n",
    "X = np.array([[[[1, 2, 3],\n",
    "                [4, 5, 6],\n",
    "                [7, 8, 9]]]])\n",
    "\n",
    "output=layer(X)\n",
    "\n",
    "print(output.shape)\n"
   ],
   "id": "5ddf3047980034fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 3, 3)\n",
      "(2,)\n",
      "Padded Input:\n",
      "[[[[0 0 0 0 0]\n",
      "   [0 1 2 3 0]\n",
      "   [0 4 5 6 0]\n",
      "   [0 7 8 9 0]\n",
      "   [0 0 0 0 0]]]]\n",
      "Convolution Output:\n",
      "[[[[12. 21. 16.]\n",
      "   [27. 45. 33.]\n",
      "   [24. 39. 28.]]\n",
      "\n",
      "  [[24. 42. 32.]\n",
      "   [54. 90. 66.]\n",
      "   [48. 78. 56.]]]]\n",
      "(1, 2, 3, 3)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T10:00:59.210594Z",
     "start_time": "2025-04-03T10:00:59.205105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ====== 反向传播测试 ======\n",
    "# 1. 定义损失函数（假设损失为输出的总和）\n",
    "loss = np.sum(output)\n",
    "print(\"初始损失值:\", loss)\n",
    "\n",
    "# 2. 反向传播计算梯度\n",
    "# 生成模拟的顶层梯度（与输出形状相同，全1）\n",
    "dout = np.ones_like(output)\n",
    "dx = layer.backward(dout)\n",
    "\n",
    "# 3. 打印反向传播得到的梯度\n",
    "print(\"\\n=== 反向传播梯度 ===\")\n",
    "print(\"卷积核梯度 (W):\")\n",
    "print(layer.grads['W'].round(4))  # 形状 (2,1,3,3)\n",
    "print(\"\\n偏置梯度 (b):\")\n",
    "print(layer.grads['b'].round(4))  # 形状 (2,)\n",
    "print(\"\\n输入梯度 (dX):\")\n",
    "print(dx.round(4))                # 形状 (1,1,3,3)\n",
    "\n"
   ],
   "id": "e09cb119f4411388",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始损失值: 735.0\n",
      "\n",
      "=== 反向传播梯度 ===\n",
      "卷积核梯度 (W):\n",
      "[[[[12. 21. 16.]\n",
      "   [27. 45. 33.]\n",
      "   [24. 39. 28.]]]\n",
      "\n",
      "\n",
      " [[[12. 21. 16.]\n",
      "   [27. 45. 33.]\n",
      "   [24. 39. 28.]]]]\n",
      "\n",
      "偏置梯度 (b):\n",
      "[9. 9.]\n",
      "\n",
      "输入梯度 (dX):\n",
      "[[[[12. 18. 12.]\n",
      "   [18. 27. 18.]\n",
      "   [12. 18. 12.]]]]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "从上面的结果来看，卷积核梯度正确，dX正确，db怎么算？db是每个核的输出全部+b，所以是9？\n",
    "\n"
   ],
   "id": "62816c00c5c0273a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T11:56:22.479830Z",
     "start_time": "2025-04-08T11:56:22.473742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layer=conv2D(in_channels=1,out_channels=2,kernel_size=3,stride=1,padding=1)\n",
    "\n",
    "layer.filters = np.array([\n",
    "    [[[2, 1, 1],  \n",
    "      [1, 1, 1],  \n",
    "      [1, 1, 1]]],  # 第一组卷积核（全 1），形状 (1,3,3)\n",
    "\n",
    "    [[[3, 1, 1],  \n",
    "      [1, 1, 1],  \n",
    "      [1, 1, 1]]],  # 第二组卷积核（全 2），形状 (1,3,3)\n",
    "])\n",
    "\n",
    "\n",
    "layer.bias = np.array([0, 0]) # 设定偏置为 0\n",
    "print(layer.filters.shape)\n",
    "print(layer.bias.shape)\n",
    "\n",
    "X = np.array([[[[1, 2, 3],\n",
    "                [4, 5, 6],\n",
    "                [7, 8, 9]]]])\n",
    "\n",
    "output=layer(X)\n",
    "\n",
    "print(output.shape)"
   ],
   "id": "9bbb9b1e09369240",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 3, 3)\n",
      "(2,)\n",
      "Padded Input:\n",
      "[[[[0 0 0 0 0]\n",
      "   [0 1 2 3 0]\n",
      "   [0 4 5 6 0]\n",
      "   [0 7 8 9 0]\n",
      "   [0 0 0 0 0]]]]\n",
      "Convolution Output:\n",
      "[[[[12. 21. 16.]\n",
      "   [27. 46. 35.]\n",
      "   [24. 43. 33.]]\n",
      "\n",
      "  [[12. 21. 16.]\n",
      "   [27. 47. 37.]\n",
      "   [24. 47. 38.]]]]\n",
      "(1, 2, 3, 3)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T11:56:23.698682Z",
     "start_time": "2025-04-08T11:56:23.693726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss = np.sum(output)\n",
    "print(\"初始损失值:\", loss)\n",
    "\n",
    "# 2. 反向传播计算梯度\n",
    "# 生成模拟的顶层梯度（与输出形状相同，全1）\n",
    "dout = np.ones_like(output)\n",
    "dx = layer.backward(dout)\n",
    "\n",
    "# 3. 打印反向传播得到的梯度\n",
    "print(\"\\n=== 反向传播梯度 ===\")\n",
    "print(\"卷积核梯度 (W):\")\n",
    "print(layer.grads['W'].round(4))  # 形状 (2,1,3,3)\n",
    "print(\"\\n偏置梯度 (b):\")\n",
    "print(layer.grads['b'].round(4))  # 形状 (2,)\n",
    "print(\"\\n输入梯度 (dX):\")\n",
    "print(dx.round(4))                # 形状 (1,1,3,3)"
   ],
   "id": "b34a181bfb8e84c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始损失值: 526.0\n",
      "\n",
      "=== 反向传播梯度 ===\n",
      "卷积核梯度 (W):\n",
      "[[[[12. 21. 16.]\n",
      "   [27. 45. 33.]\n",
      "   [24. 39. 28.]]]\n",
      "\n",
      "\n",
      " [[[12. 21. 16.]\n",
      "   [27. 45. 33.]\n",
      "   [24. 39. 28.]]]]\n",
      "\n",
      "偏置梯度 (b):\n",
      "[9. 9.]\n",
      "\n",
      "输入梯度 (dX):\n",
      "[[[[11. 15.  8.]\n",
      "   [15. 21. 12.]\n",
      "   [ 8. 12.  8.]]]]\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
